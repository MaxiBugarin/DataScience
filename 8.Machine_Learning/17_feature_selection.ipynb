{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "pygments_lexer": "ipython3",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "nbconvert_exporter": "python",
      "version": "3.7.1",
      "mimetype": "text/x-python",
      "name": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "16_feature_selection.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/al34n1x/DataScience/blob/master/99.Machine_Learning/17_feature_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wA0qmz5VWXW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# Selección de variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPZbcVBpVWXW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## a. Filtrado de atributos\n",
        "\n",
        "\n",
        "Con el objetivo de reducir la dimensionalidad, otra técnica es la del filtrado de atributos. Los pasos a seguir son los siguientes.\n",
        "\n",
        "\n",
        "- Estudiar cada una de las características o atributos que contiene el conjunto de datos.\n",
        "- Localizar redundancia entre esos atributos.\n",
        "- Eliminar esas variables redundantes, de forma que sólo quede una variable que exprese una información.\n",
        "\n",
        "\n",
        "*Ejemplo*. Si dentro del set de datos, se tienen varias características que hacen referencia a las mismas medidas en centímetros y en pulgadas, se deben eliminar todas aquellas variables en pulgadas ya que no aportan ninguna información. Se mantienen las variables en centímetros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIjNlSXdVWXX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## b. Eliminar variables con baja varianza\n",
        " \n",
        "Eliminar aquellas variables cuya varianza no llega a cierto umbral. Por defecto, eliminar todas las variables con varianza cero (donde todos los valores son iguales). Las variables con baja varianza obligan a hacer el modelo más complejo, y se pierde “tiempo” intentando ajustar variables que no aportan nada\n",
        "\n",
        "En Scikit-Learn la función `VarianceThreshold` permite eliminar aquellas variables cuya varianza no llega cierto umbral. Por defecto, elimina todas las variables con varianza cero, donde todos los valores son iguales, o cercana a cero.\n",
        "\n",
        "*Ejemplo*. Imagina que tenemos un dataset con variables categóricas y queremos eliminar aquellas con mas de un 80% de variables iguales. La varianza de variables booleanas es \"p(1-p)\" donde p es el porcentaje que queramos filtrar, luego `var = (0.8*(1-0.8))`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f1LZCi8VWXX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "566c74bf-3fc7-4597-c7e3-6a7f3469ddf3"
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "X = [[0, 0, 3], [0, 2, 0], [1, 0, 0], [0, 2, 3], [0, 2, 0], [0, 2, 3]]\n",
        "\n",
        "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
        "sel.fit_transform(X)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 3],\n",
              "       [2, 0],\n",
              "       [0, 0],\n",
              "       [2, 3],\n",
              "       [2, 0],\n",
              "       [2, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWe4JEnHVWXa",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Ha eliminado la columna de los unos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugvW2FzWVWXb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## c. Selección de variables en base a estadísticos\n",
        "\n",
        "Selecciona las mejores variables en base a calculos estadisticos.\n",
        "\n",
        "* `SelectKBest`: Se queda con las k mejores variables\n",
        "* `SelectPercentile`: Se queda con un porcentaje de las mejores variables\n",
        "\n",
        "Ejemplo de los estadisticos que usan son:\n",
        "\n",
        "* **Chi-cuadrado** entre variables (no puede haber variables negativas). Este estadistico mide dependencia entre variables, por lo que elimina aquellas que menos relación tienen con las demás (las más independientes), ya que son las que menos ayudan en la clasificación\n",
        "\n",
        "\n",
        "* **f_regression**: se realiza un modelo lineal entre cada variable y la variable objetivo y se mide la correlacion entre ellos (se devuelve como un p-value [Math: F-test comparando si varianzas son iguales]).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFg0Hx_mVWXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgVp9BCaVWXe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "641b4d80-0ef7-48f2-c308-0ae0afd12664"
      },
      "source": [
        "iris = load_iris()\n",
        "features, label = iris.data, iris.target\n",
        "\n",
        "features_new = SelectKBest(chi2, k=3).fit_transform(features, label)\n",
        "\n",
        "features_new"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 1.4, 0.2],\n",
              "       [4.9, 1.4, 0.2],\n",
              "       [4.7, 1.3, 0.2],\n",
              "       [4.6, 1.5, 0.2],\n",
              "       [5. , 1.4, 0.2],\n",
              "       [5.4, 1.7, 0.4],\n",
              "       [4.6, 1.4, 0.3],\n",
              "       [5. , 1.5, 0.2],\n",
              "       [4.4, 1.4, 0.2],\n",
              "       [4.9, 1.5, 0.1],\n",
              "       [5.4, 1.5, 0.2],\n",
              "       [4.8, 1.6, 0.2],\n",
              "       [4.8, 1.4, 0.1],\n",
              "       [4.3, 1.1, 0.1],\n",
              "       [5.8, 1.2, 0.2],\n",
              "       [5.7, 1.5, 0.4],\n",
              "       [5.4, 1.3, 0.4],\n",
              "       [5.1, 1.4, 0.3],\n",
              "       [5.7, 1.7, 0.3],\n",
              "       [5.1, 1.5, 0.3],\n",
              "       [5.4, 1.7, 0.2],\n",
              "       [5.1, 1.5, 0.4],\n",
              "       [4.6, 1. , 0.2],\n",
              "       [5.1, 1.7, 0.5],\n",
              "       [4.8, 1.9, 0.2],\n",
              "       [5. , 1.6, 0.2],\n",
              "       [5. , 1.6, 0.4],\n",
              "       [5.2, 1.5, 0.2],\n",
              "       [5.2, 1.4, 0.2],\n",
              "       [4.7, 1.6, 0.2],\n",
              "       [4.8, 1.6, 0.2],\n",
              "       [5.4, 1.5, 0.4],\n",
              "       [5.2, 1.5, 0.1],\n",
              "       [5.5, 1.4, 0.2],\n",
              "       [4.9, 1.5, 0.2],\n",
              "       [5. , 1.2, 0.2],\n",
              "       [5.5, 1.3, 0.2],\n",
              "       [4.9, 1.4, 0.1],\n",
              "       [4.4, 1.3, 0.2],\n",
              "       [5.1, 1.5, 0.2],\n",
              "       [5. , 1.3, 0.3],\n",
              "       [4.5, 1.3, 0.3],\n",
              "       [4.4, 1.3, 0.2],\n",
              "       [5. , 1.6, 0.6],\n",
              "       [5.1, 1.9, 0.4],\n",
              "       [4.8, 1.4, 0.3],\n",
              "       [5.1, 1.6, 0.2],\n",
              "       [4.6, 1.4, 0.2],\n",
              "       [5.3, 1.5, 0.2],\n",
              "       [5. , 1.4, 0.2],\n",
              "       [7. , 4.7, 1.4],\n",
              "       [6.4, 4.5, 1.5],\n",
              "       [6.9, 4.9, 1.5],\n",
              "       [5.5, 4. , 1.3],\n",
              "       [6.5, 4.6, 1.5],\n",
              "       [5.7, 4.5, 1.3],\n",
              "       [6.3, 4.7, 1.6],\n",
              "       [4.9, 3.3, 1. ],\n",
              "       [6.6, 4.6, 1.3],\n",
              "       [5.2, 3.9, 1.4],\n",
              "       [5. , 3.5, 1. ],\n",
              "       [5.9, 4.2, 1.5],\n",
              "       [6. , 4. , 1. ],\n",
              "       [6.1, 4.7, 1.4],\n",
              "       [5.6, 3.6, 1.3],\n",
              "       [6.7, 4.4, 1.4],\n",
              "       [5.6, 4.5, 1.5],\n",
              "       [5.8, 4.1, 1. ],\n",
              "       [6.2, 4.5, 1.5],\n",
              "       [5.6, 3.9, 1.1],\n",
              "       [5.9, 4.8, 1.8],\n",
              "       [6.1, 4. , 1.3],\n",
              "       [6.3, 4.9, 1.5],\n",
              "       [6.1, 4.7, 1.2],\n",
              "       [6.4, 4.3, 1.3],\n",
              "       [6.6, 4.4, 1.4],\n",
              "       [6.8, 4.8, 1.4],\n",
              "       [6.7, 5. , 1.7],\n",
              "       [6. , 4.5, 1.5],\n",
              "       [5.7, 3.5, 1. ],\n",
              "       [5.5, 3.8, 1.1],\n",
              "       [5.5, 3.7, 1. ],\n",
              "       [5.8, 3.9, 1.2],\n",
              "       [6. , 5.1, 1.6],\n",
              "       [5.4, 4.5, 1.5],\n",
              "       [6. , 4.5, 1.6],\n",
              "       [6.7, 4.7, 1.5],\n",
              "       [6.3, 4.4, 1.3],\n",
              "       [5.6, 4.1, 1.3],\n",
              "       [5.5, 4. , 1.3],\n",
              "       [5.5, 4.4, 1.2],\n",
              "       [6.1, 4.6, 1.4],\n",
              "       [5.8, 4. , 1.2],\n",
              "       [5. , 3.3, 1. ],\n",
              "       [5.6, 4.2, 1.3],\n",
              "       [5.7, 4.2, 1.2],\n",
              "       [5.7, 4.2, 1.3],\n",
              "       [6.2, 4.3, 1.3],\n",
              "       [5.1, 3. , 1.1],\n",
              "       [5.7, 4.1, 1.3],\n",
              "       [6.3, 6. , 2.5],\n",
              "       [5.8, 5.1, 1.9],\n",
              "       [7.1, 5.9, 2.1],\n",
              "       [6.3, 5.6, 1.8],\n",
              "       [6.5, 5.8, 2.2],\n",
              "       [7.6, 6.6, 2.1],\n",
              "       [4.9, 4.5, 1.7],\n",
              "       [7.3, 6.3, 1.8],\n",
              "       [6.7, 5.8, 1.8],\n",
              "       [7.2, 6.1, 2.5],\n",
              "       [6.5, 5.1, 2. ],\n",
              "       [6.4, 5.3, 1.9],\n",
              "       [6.8, 5.5, 2.1],\n",
              "       [5.7, 5. , 2. ],\n",
              "       [5.8, 5.1, 2.4],\n",
              "       [6.4, 5.3, 2.3],\n",
              "       [6.5, 5.5, 1.8],\n",
              "       [7.7, 6.7, 2.2],\n",
              "       [7.7, 6.9, 2.3],\n",
              "       [6. , 5. , 1.5],\n",
              "       [6.9, 5.7, 2.3],\n",
              "       [5.6, 4.9, 2. ],\n",
              "       [7.7, 6.7, 2. ],\n",
              "       [6.3, 4.9, 1.8],\n",
              "       [6.7, 5.7, 2.1],\n",
              "       [7.2, 6. , 1.8],\n",
              "       [6.2, 4.8, 1.8],\n",
              "       [6.1, 4.9, 1.8],\n",
              "       [6.4, 5.6, 2.1],\n",
              "       [7.2, 5.8, 1.6],\n",
              "       [7.4, 6.1, 1.9],\n",
              "       [7.9, 6.4, 2. ],\n",
              "       [6.4, 5.6, 2.2],\n",
              "       [6.3, 5.1, 1.5],\n",
              "       [6.1, 5.6, 1.4],\n",
              "       [7.7, 6.1, 2.3],\n",
              "       [6.3, 5.6, 2.4],\n",
              "       [6.4, 5.5, 1.8],\n",
              "       [6. , 4.8, 1.8],\n",
              "       [6.9, 5.4, 2.1],\n",
              "       [6.7, 5.6, 2.4],\n",
              "       [6.9, 5.1, 2.3],\n",
              "       [5.8, 5.1, 1.9],\n",
              "       [6.8, 5.9, 2.3],\n",
              "       [6.7, 5.7, 2.5],\n",
              "       [6.7, 5.2, 2.3],\n",
              "       [6.3, 5. , 1.9],\n",
              "       [6.5, 5.2, 2. ],\n",
              "       [6.2, 5.4, 2.3],\n",
              "       [5.9, 5.1, 1.8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeskR6TSVWXg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## d. Usar árboles para discriminar la importancia de las variables\n",
        "\n",
        "Los arboles de decisión, por su forma interna de generar las ramas, realizan una ponderación de las variables en base a su importancia. Esto se puede aprovechar para exrtaer esa información y filtrar las variables menos importantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8dQUl3_VWXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yek6QAIoVWXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c02e8b3-3184-4d12-85b3-809587ed0f1a"
      },
      "source": [
        "iris = load_iris()\n",
        "features, label = iris.data, iris.target\n",
        "print (features.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYEQ5mA-VWXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "features_train, features_test, label_train, label_test=train_test_split(iris.data,iris.target,test_size=0.3)\n",
        "etc = ExtraTreesClassifier(n_estimators=20,max_depth=5)\n",
        "model = etc.fit(features_train,label_train)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHtRhZp0VWXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "b4e43e46-5f2f-4a5f-c667-1b5fac55a914"
      },
      "source": [
        "pd.DataFrame({'variable':iris.feature_names,\n",
        "              'importance':model.feature_importances_},\n",
        "             columns=['variable','importance'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variable</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sepal length (cm)</td>\n",
              "      <td>0.168581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sepal width (cm)</td>\n",
              "      <td>0.056578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>petal length (cm)</td>\n",
              "      <td>0.358744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>petal width (cm)</td>\n",
              "      <td>0.416097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            variable  importance\n",
              "0  sepal length (cm)    0.168581\n",
              "1   sepal width (cm)    0.056578\n",
              "2  petal length (cm)    0.358744\n",
              "3   petal width (cm)    0.416097"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMU9eNoeVWXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a00f1f6c-cca8-4162-d9c9-f9d4d579e9b3"
      },
      "source": [
        "prediction=model.predict(features_test)\n",
        "accuracy_score(prediction,label_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9555555555555556"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi_P-WTOVWXr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26a8c9a9-7f6a-4470-d8ff-fb6bf2dd66de"
      },
      "source": [
        "help(SelectFromModel)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class SelectFromModel in module sklearn.feature_selection._from_model:\n",
            "\n",
            "class SelectFromModel(sklearn.base.MetaEstimatorMixin, sklearn.feature_selection._base.SelectorMixin, sklearn.base.BaseEstimator)\n",
            " |  Meta-transformer for selecting features based on importance weights.\n",
            " |  \n",
            " |  .. versionadded:: 0.17\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  estimator : object\n",
            " |      The base estimator from which the transformer is built.\n",
            " |      This can be both a fitted (if ``prefit`` is set to True)\n",
            " |      or a non-fitted estimator. The estimator must have either a\n",
            " |      ``feature_importances_`` or ``coef_`` attribute after fitting.\n",
            " |  \n",
            " |  threshold : string, float, optional default None\n",
            " |      The threshold value to use for feature selection. Features whose\n",
            " |      importance is greater or equal are kept while the others are\n",
            " |      discarded. If \"median\" (resp. \"mean\"), then the ``threshold`` value is\n",
            " |      the median (resp. the mean) of the feature importances. A scaling\n",
            " |      factor (e.g., \"1.25*mean\") may also be used. If None and if the\n",
            " |      estimator has a parameter penalty set to l1, either explicitly\n",
            " |      or implicitly (e.g, Lasso), the threshold used is 1e-5.\n",
            " |      Otherwise, \"mean\" is used by default.\n",
            " |  \n",
            " |  prefit : bool, default False\n",
            " |      Whether a prefit model is expected to be passed into the constructor\n",
            " |      directly or not. If True, ``transform`` must be called directly\n",
            " |      and SelectFromModel cannot be used with ``cross_val_score``,\n",
            " |      ``GridSearchCV`` and similar utilities that clone the estimator.\n",
            " |      Otherwise train the model using ``fit`` and then ``transform`` to do\n",
            " |      feature selection.\n",
            " |  \n",
            " |  norm_order : non-zero int, inf, -inf, default 1\n",
            " |      Order of the norm used to filter the vectors of coefficients below\n",
            " |      ``threshold`` in the case where the ``coef_`` attribute of the\n",
            " |      estimator is of dimension 2.\n",
            " |  \n",
            " |  max_features : int or None, optional\n",
            " |      The maximum number of features selected scoring above ``threshold``.\n",
            " |      To disable ``threshold`` and only select based on ``max_features``,\n",
            " |      set ``threshold=-np.inf``.\n",
            " |  \n",
            " |      .. versionadded:: 0.20\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  estimator_ : an estimator\n",
            " |      The base estimator from which the transformer is built.\n",
            " |      This is stored only when a non-fitted estimator is passed to the\n",
            " |      ``SelectFromModel``, i.e when prefit is False.\n",
            " |  \n",
            " |  threshold_ : float\n",
            " |      The threshold value used for feature selection.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  Allows NaN/Inf in the input if the underlying estimator does as well.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn.feature_selection import SelectFromModel\n",
            " |  >>> from sklearn.linear_model import LogisticRegression\n",
            " |  >>> X = [[ 0.87, -1.34,  0.31 ],\n",
            " |  ...      [-2.79, -0.02, -0.85 ],\n",
            " |  ...      [-1.34, -0.48, -2.55 ],\n",
            " |  ...      [ 1.92,  1.48,  0.65 ]]\n",
            " |  >>> y = [0, 1, 0, 1]\n",
            " |  >>> selector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)\n",
            " |  >>> selector.estimator_.coef_\n",
            " |  array([[-0.3252302 ,  0.83462377,  0.49750423]])\n",
            " |  >>> selector.threshold_\n",
            " |  0.55245...\n",
            " |  >>> selector.get_support()\n",
            " |  array([False,  True, False])\n",
            " |  >>> selector.transform(X)\n",
            " |  array([[-1.34],\n",
            " |         [-0.02],\n",
            " |         [-0.48],\n",
            " |         [ 1.48]])\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      SelectFromModel\n",
            " |      sklearn.base.MetaEstimatorMixin\n",
            " |      sklearn.feature_selection._base.SelectorMixin\n",
            " |      sklearn.base.TransformerMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, estimator, threshold=None, prefit=False, norm_order=1, max_features=None)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y=None, **fit_params)\n",
            " |      Fit the SelectFromModel meta-transformer.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          The training input samples.\n",
            " |      \n",
            " |      y : array-like, shape (n_samples,)\n",
            " |          The target values (integers that correspond to classes in\n",
            " |          classification, real numbers in regression).\n",
            " |      \n",
            " |      **fit_params : Other estimator specific parameters\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |  \n",
            " |  partial_fit(self, X, y=None, **fit_params)\n",
            " |      Fit the SelectFromModel meta-transformer only once.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          The training input samples.\n",
            " |      \n",
            " |      y : array-like, shape (n_samples,)\n",
            " |          The target values (integers that correspond to classes in\n",
            " |          classification, real numbers in regression).\n",
            " |      \n",
            " |      **fit_params : Other estimator specific parameters\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  threshold_\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.feature_selection._base.SelectorMixin:\n",
            " |  \n",
            " |  get_support(self, indices=False)\n",
            " |      Get a mask, or integer index, of the features selected\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      indices : boolean (default False)\n",
            " |          If True, the return value will be an array of integers, rather\n",
            " |          than a boolean mask.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      support : array\n",
            " |          An index that selects the retained features from a feature vector.\n",
            " |          If `indices` is False, this is a boolean array of shape\n",
            " |          [# input features], in which an element is True iff its\n",
            " |          corresponding feature is selected for retention. If `indices` is\n",
            " |          True, this is an integer array of shape [# output features] whose\n",
            " |          values are indices into the input feature vector.\n",
            " |  \n",
            " |  inverse_transform(self, X)\n",
            " |      Reverse the transformation operation\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array of shape [n_samples, n_selected_features]\n",
            " |          The input samples.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_r : array of shape [n_samples, n_original_features]\n",
            " |          `X` with columns of zeros inserted where features would have\n",
            " |          been removed by :meth:`transform`.\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Reduce X to the selected features.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array of shape [n_samples, n_features]\n",
            " |          The input samples.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_r : array of shape [n_samples, n_selected_features]\n",
            " |          The input samples with only the selected features.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.TransformerMixin:\n",
            " |  \n",
            " |  fit_transform(self, X, y=None, **fit_params)\n",
            " |      Fit to data, then transform it.\n",
            " |      \n",
            " |      Fits transformer to X and y with optional parameters fit_params\n",
            " |      and returns a transformed version of X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : numpy array of shape [n_samples, n_features]\n",
            " |          Training set.\n",
            " |      \n",
            " |      y : numpy array of shape [n_samples]\n",
            " |          Target values.\n",
            " |      \n",
            " |      **fit_params : dict\n",
            " |          Additional fit parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
            " |          Transformed array.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : mapping of string to any\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as pipelines). The latter have parameters of the form\n",
            " |      ``<component>__<parameter>`` so that it's possible to update each\n",
            " |      component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Estimator instance.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlTRVvN_VWXt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Al establecer el valor umbral en 0.2 nos estaríamos quedando con las variables petal length y petal width"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saotmeiYVWXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selection = SelectFromModel(etc, prefit = False,threshold=0.2) # filters the variables according to a threshold"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyXn_zbpVWXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selection.fit(features_train,label_train)\n",
        "features_train_new = selection.transform(features_train)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu57MvfxVWXz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Hay que hacer también la selección de variables para el conjunto de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt3DPdv0VWX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_test_new = selection.transform(features_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP19uw21VWX1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Comprobamos que efectivamente selecciona únicamente dos variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBAVo8MHVWX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1aa9da60-9631-4f66-b101-0ced9a0bd0d0"
      },
      "source": [
        "features_train_new.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRYgB_1tVWX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60fe142b-a081-416a-f561-43d217bb7ba0"
      },
      "source": [
        "model = etc.fit(features_train_new,label_train)\n",
        "prediction=model.predict(features_test_new)\n",
        "accuracy_score(prediction,label_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7sbsfH5VWX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef2d0ec9-ba69-4f31-cb85-ad841f162500"
      },
      "source": [
        "model.feature_importances_"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5278309, 0.4721691])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnxQA5A0VWX9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## f. Selección hacia atrás"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnSOHy-sVWX9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "`sklearn` incorpora una implementación de la selección hacia atrás llamada *Recursive Feature Elimination*. Utilizando el algoritmo de aprendizaje que queramos (el estimador), él se encarga de ir eliminando variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXvIBDmVVWX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYsHKuDUVWYA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Para ello vamos a usar el conjunto de datos de ejemplo `breast_cancer`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVOwgSH2VWYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cancer = load_breast_cancer()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWoIX46rVWYC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "El estimador que vamos a usar es un random forest, al que le definiriemos el número de árboles y la profundidad de forma manual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlcbFyE5VWYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators=100,max_depth=10)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV1WiA_AVWYF",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "RFECV es un método que nos permite hacer la selección hacia atrás usando una validación cruzada y además, que es lo más importante, nos permite definir la métrica y obtener la puntuación para cada subset de variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agbuAhPcVWYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfecv=RFECV(estimator=rf, step=1, cv=StratifiedKFold(5),\n",
        "              scoring='roc_auc',verbose=1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFv-TaMNVWYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f132f80-c6b1-4832-a440-a6106d2a3321"
      },
      "source": [
        "rfecv.fit(cancer.data,cancer.target)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 30 features.\n",
            "Fitting estimator with 29 features.\n",
            "Fitting estimator with 28 features.\n",
            "Fitting estimator with 27 features.\n",
            "Fitting estimator with 26 features.\n",
            "Fitting estimator with 25 features.\n",
            "Fitting estimator with 24 features.\n",
            "Fitting estimator with 23 features.\n",
            "Fitting estimator with 22 features.\n",
            "Fitting estimator with 21 features.\n",
            "Fitting estimator with 20 features.\n",
            "Fitting estimator with 19 features.\n",
            "Fitting estimator with 18 features.\n",
            "Fitting estimator with 17 features.\n",
            "Fitting estimator with 16 features.\n",
            "Fitting estimator with 15 features.\n",
            "Fitting estimator with 14 features.\n",
            "Fitting estimator with 13 features.\n",
            "Fitting estimator with 12 features.\n",
            "Fitting estimator with 11 features.\n",
            "Fitting estimator with 10 features.\n",
            "Fitting estimator with 9 features.\n",
            "Fitting estimator with 8 features.\n",
            "Fitting estimator with 7 features.\n",
            "Fitting estimator with 6 features.\n",
            "Fitting estimator with 5 features.\n",
            "Fitting estimator with 4 features.\n",
            "Fitting estimator with 3 features.\n",
            "Fitting estimator with 2 features.\n",
            "Fitting estimator with 30 features.\n",
            "Fitting estimator with 29 features.\n",
            "Fitting estimator with 28 features.\n",
            "Fitting estimator with 27 features.\n",
            "Fitting estimator with 26 features.\n",
            "Fitting estimator with 25 features.\n",
            "Fitting estimator with 24 features.\n",
            "Fitting estimator with 23 features.\n",
            "Fitting estimator with 22 features.\n",
            "Fitting estimator with 21 features.\n",
            "Fitting estimator with 20 features.\n",
            "Fitting estimator with 19 features.\n",
            "Fitting estimator with 18 features.\n",
            "Fitting estimator with 17 features.\n",
            "Fitting estimator with 16 features.\n",
            "Fitting estimator with 15 features.\n",
            "Fitting estimator with 14 features.\n",
            "Fitting estimator with 13 features.\n",
            "Fitting estimator with 12 features.\n",
            "Fitting estimator with 11 features.\n",
            "Fitting estimator with 10 features.\n",
            "Fitting estimator with 9 features.\n",
            "Fitting estimator with 8 features.\n",
            "Fitting estimator with 7 features.\n",
            "Fitting estimator with 6 features.\n",
            "Fitting estimator with 5 features.\n",
            "Fitting estimator with 4 features.\n",
            "Fitting estimator with 3 features.\n",
            "Fitting estimator with 2 features.\n",
            "Fitting estimator with 30 features.\n",
            "Fitting estimator with 29 features.\n",
            "Fitting estimator with 28 features.\n",
            "Fitting estimator with 27 features.\n",
            "Fitting estimator with 26 features.\n",
            "Fitting estimator with 25 features.\n",
            "Fitting estimator with 24 features.\n",
            "Fitting estimator with 23 features.\n",
            "Fitting estimator with 22 features.\n",
            "Fitting estimator with 21 features.\n",
            "Fitting estimator with 20 features.\n",
            "Fitting estimator with 19 features.\n",
            "Fitting estimator with 18 features.\n",
            "Fitting estimator with 17 features.\n",
            "Fitting estimator with 16 features.\n",
            "Fitting estimator with 15 features.\n",
            "Fitting estimator with 14 features.\n",
            "Fitting estimator with 13 features.\n",
            "Fitting estimator with 12 features.\n",
            "Fitting estimator with 11 features.\n",
            "Fitting estimator with 10 features.\n",
            "Fitting estimator with 9 features.\n",
            "Fitting estimator with 8 features.\n",
            "Fitting estimator with 7 features.\n",
            "Fitting estimator with 6 features.\n",
            "Fitting estimator with 5 features.\n",
            "Fitting estimator with 4 features.\n",
            "Fitting estimator with 3 features.\n",
            "Fitting estimator with 2 features.\n",
            "Fitting estimator with 30 features.\n",
            "Fitting estimator with 29 features.\n",
            "Fitting estimator with 28 features.\n",
            "Fitting estimator with 27 features.\n",
            "Fitting estimator with 26 features.\n",
            "Fitting estimator with 25 features.\n",
            "Fitting estimator with 24 features.\n",
            "Fitting estimator with 23 features.\n",
            "Fitting estimator with 22 features.\n",
            "Fitting estimator with 21 features.\n",
            "Fitting estimator with 20 features.\n",
            "Fitting estimator with 19 features.\n",
            "Fitting estimator with 18 features.\n",
            "Fitting estimator with 17 features.\n",
            "Fitting estimator with 16 features.\n",
            "Fitting estimator with 15 features.\n",
            "Fitting estimator with 14 features.\n",
            "Fitting estimator with 13 features.\n",
            "Fitting estimator with 12 features.\n",
            "Fitting estimator with 11 features.\n",
            "Fitting estimator with 10 features.\n",
            "Fitting estimator with 9 features.\n",
            "Fitting estimator with 8 features.\n",
            "Fitting estimator with 7 features.\n",
            "Fitting estimator with 6 features.\n",
            "Fitting estimator with 5 features.\n",
            "Fitting estimator with 4 features.\n",
            "Fitting estimator with 3 features.\n",
            "Fitting estimator with 2 features.\n",
            "Fitting estimator with 30 features.\n",
            "Fitting estimator with 29 features.\n",
            "Fitting estimator with 28 features.\n",
            "Fitting estimator with 27 features.\n",
            "Fitting estimator with 26 features.\n",
            "Fitting estimator with 25 features.\n",
            "Fitting estimator with 24 features.\n",
            "Fitting estimator with 23 features.\n",
            "Fitting estimator with 22 features.\n",
            "Fitting estimator with 21 features.\n",
            "Fitting estimator with 20 features.\n",
            "Fitting estimator with 19 features.\n",
            "Fitting estimator with 18 features.\n",
            "Fitting estimator with 17 features.\n",
            "Fitting estimator with 16 features.\n",
            "Fitting estimator with 15 features.\n",
            "Fitting estimator with 14 features.\n",
            "Fitting estimator with 13 features.\n",
            "Fitting estimator with 12 features.\n",
            "Fitting estimator with 11 features.\n",
            "Fitting estimator with 10 features.\n",
            "Fitting estimator with 9 features.\n",
            "Fitting estimator with 8 features.\n",
            "Fitting estimator with 7 features.\n",
            "Fitting estimator with 6 features.\n",
            "Fitting estimator with 5 features.\n",
            "Fitting estimator with 4 features.\n",
            "Fitting estimator with 3 features.\n",
            "Fitting estimator with 2 features.\n",
            "Fitting estimator with 30 features.\n",
            "Fitting estimator with 29 features.\n",
            "Fitting estimator with 28 features.\n",
            "Fitting estimator with 27 features.\n",
            "Fitting estimator with 26 features.\n",
            "Fitting estimator with 25 features.\n",
            "Fitting estimator with 24 features.\n",
            "Fitting estimator with 23 features.\n",
            "Fitting estimator with 22 features.\n",
            "Fitting estimator with 21 features.\n",
            "Fitting estimator with 20 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RFECV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
              "      estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                       class_weight=None, criterion='gini',\n",
              "                                       max_depth=10, max_features='auto',\n",
              "                                       max_leaf_nodes=None, max_samples=None,\n",
              "                                       min_impurity_decrease=0.0,\n",
              "                                       min_impurity_split=None,\n",
              "                                       min_samples_leaf=1, min_samples_split=2,\n",
              "                                       min_weight_fraction_leaf=0.0,\n",
              "                                       n_estimators=100, n_jobs=None,\n",
              "                                       oob_score=False, random_state=None,\n",
              "                                       verbose=0, warm_start=False),\n",
              "      min_features_to_select=1, n_jobs=None, scoring='roc_auc', step=1,\n",
              "      verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRfNw67UVWYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cfdc807c-e771-4182-b396-fe20830a474b"
      },
      "source": [
        "rfecv.grid_scores_"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.94676179, 0.96678138, 0.97724481, 0.97852977, 0.98249728,\n",
              "       0.98240388, 0.98501909, 0.9877005 , 0.99040616, 0.98978492,\n",
              "       0.99073528, 0.99070879, 0.99054376, 0.98816314, 0.99015557,\n",
              "       0.99080299, 0.99044956, 0.99110089, 0.99188075, 0.98885097,\n",
              "       0.98819666, 0.98976405, 0.99017722, 0.98984463, 0.98962507,\n",
              "       0.99116577, 0.98981437, 0.98789844, 0.99142283, 0.99038266])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw3kQqGYVWYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "c7e3476a-dc01-4eb9-e52e-b4b17431ed0e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of selected variables\")\n",
        "plt.ylabel(\"AUC\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwCNqrzNVWYQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# Ejercicios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBvCnvHVWYQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Ejercicio 1\n",
        "\n",
        "Elige el dataset que quieras y calcula la varianza de cada variable. ¿Quitarías alguna variable basándote en este principio?."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkHx3I8RVWYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Respuesta aqui"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfc2LB2aVWYS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Ejercicio 2\n",
        "\n",
        "Elige el mismo dataset, calcula las varianzas y quedate con las tres mejores variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFf9MS2HVWYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Respuesta aqui"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG589mQpVWYU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Ejercicio 3\n",
        "\n",
        "Elige el mismo dataset de antes, y quedate con las 3 mejores variables con este método. ¿Coinciden?.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL-FZQM4VWYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Respuesta aqui"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}