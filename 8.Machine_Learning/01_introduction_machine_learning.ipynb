{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "pygments_lexer": "ipython3",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "nbconvert_exporter": "python",
      "version": "3.7.1",
      "mimetype": "text/x-python",
      "name": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "01_introduction_machine_learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/al34n1x/DataScience/blob/master/8.Machine_Learning/01_introduction_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRWL5MOlYocc"
      },
      "source": [
        "\n",
        "\n",
        "# Machine Learning con Python\n",
        "\n",
        "Haremos un ejercicio básico de un problema supervisado de regresión para predecir el costo de una casa y veremos como se puede resolver en Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0KfDO34Yh8S"
      },
      "source": [
        "\n",
        "\n",
        "## Introducción\n",
        "\n",
        "Los primeros pasos a seguir para ajustar un modelo de predicción usando Python son:\n",
        "\n",
        "1. **Preparar los datos**. Como hemos visto, para llegar a este punto hemos aprendido a cargar los datos de diferentes maneras y de diferentes fuentes, a limpiarlos, a organizarlos, agruparlos, etc, y a hacer un análisis exploratorio de datos con el objetivo de entender mejor los datos y el problema.\n",
        "\n",
        "2. **Identificar la variable objetivo**. Si ya está definida, identificarla y separarla del resto de las variables independientes. Si no está definida, construírla a partir del contexto del problema.\n",
        "\n",
        "3. **División train/test de los datos**. La división puede ser aleatoria o predefinida según el contexto, con muestreo, despendiendo de la naturaleza del problema.\n",
        "\n",
        "4. **Instanciación del modelo para el entrenamiento**. Usaremos una librería para cargar los algoritmos predefinidos llamada sklearn. \n",
        "\n",
        "5. **Ajuste del modelo**. Utilizaremos el método ```fit``` del modelo.\n",
        "\n",
        "6. **Predicción**. Utilización del método ```predict``` del modelo.\n",
        "\n",
        "7. **Elección y implemetación de un métrica**. Para poder estimar el error de prueba."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyDW9dpbR98R"
      },
      "source": [
        "\n",
        "\n",
        "Primeramente vamos a llamar a la librería ```scikit-learn```, ésta contiene varios módulos en donde están cargadas las diferentes herramientas de ML.\n",
        "Por ejemplo de model_selection obtendremos el método ```train_test_split```, de ```linear_model``` obtendremos el objeto ```LinearRegression``` la cuál contiene el algorítmo de regresión lineal cargado, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku2MRUn_ermJ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HXUKiXzemiP"
      },
      "source": [
        "\n",
        "\n",
        "## Preparar los datos: valores de las casas de los suburbios de Boston\n",
        "\n",
        "* [Fuente:](http://cdn.jsdelivr.net/gh/al34n1x/DataScience/data/Boston.csv)\n",
        "\n",
        "\n",
        "\n",
        "Lo podemos leer de la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASunJ-aBmS5c"
      },
      "source": [
        "df = pd.read_csv('https://github.com/al34n1x/DataScience/raw/master/data/Boston.csv',squeeze=True, delimiter=',', header=0, index_col=0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFPll5aZUDlE"
      },
      "source": [
        "\n",
        "\n",
        "El archivo contiene datos de las casas de los suburbios de Boston, cada registro representa una casa y tiene varios atributos.\n",
        "\n",
        "Tanto caracteristicas físicas de la casa como atributos demográficos de la zona: número de habitaciones, el procentaje de crimen por zona, el ratio de alumno/maestro, etc... \n",
        "\n",
        "Estos datos ya vienen en una estructura que, a parte de estructurada de manera adecuada, no viene con registro repetidos, nulos, o atípicos. Podemos decir que fueron previamente tratados y que están listos para entrenar un modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEwn_Wx9kLUr"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xO3I8xm539D"
      },
      "source": [
        "\n",
        "\n",
        "## Identificar la variable objetivo\n",
        "En este caso la variable objetivo está dada, no tenemos que hacer una transformación para obtenerla, simplemente la obtenemos a partir de la columna del dataframe ```df```. Las demás columnas ya son variables númericas que pueden servir como *input* de un modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8A0cGTq57LA"
      },
      "source": [
        "features = list(df.columns)[:-1]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5xFi_rD6dbf"
      },
      "source": [
        "X = df[features]\n",
        "y = df.medv"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rghisksijg44"
      },
      "source": [
        "\n",
        "\n",
        "## Hacer la separacion train/test\n",
        "El método ```train_test_split``` regresa 4 outputs, las features divididas en entrenamiento y prueba, y la variable objetivo divida en entrenamiento y prueba respectivamente. Por convención (como en muchos casos en Python) en este contexto les llamamos ```X_train```, ```X_test```, ```y_train```, ```y_test```.\n",
        "\n",
        "Por defecto se hace una particion aleatoria del 75% de entrenamiento, 25% de prueba.\n",
        "\n",
        "* X_train:  incluye todas las variables independientes, estas se usarán para entrenar el modelo, también como hemos especificado test_size = 25%, esto significa que el 75% de las observaciones de sus datos completos se usarán para entrenar / ajustar el modelo y 25% % se utilizará para probar el modelo.\n",
        "\n",
        "* X_test: esta es la porción restante del 25% de las variables independientes de los datos que no se usarán en la fase de entrenamiento y se usarán para hacer predicciones para probar la precisión del modelo.\n",
        "\n",
        "* y_train: esta es su variable dependiente que debe predecirse con este modelo, esto incluye etiquetas de categoría contra sus variables independientes, necesitamos especificar nuestra variable dependiente mientras entrenamos / ajustamos el modelo.\n",
        "\n",
        "* y_test: estos datos tienen etiquetas de categoría para sus datos de prueba, estas etiquetas se utilizarán para probar la precisión entre las categorías reales y previstas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bIoh104j7ex"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POTA8L7ErSke"
      },
      "source": [
        "print('Features_train:',X_train.shape)\n",
        "print('Features_test:',X_test.shape)\n",
        "print('Target_train:',y_train.shape)\n",
        "print('Target_test:',y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUx-Kgqqkr1G"
      },
      "source": [
        "\n",
        "\n",
        "## Instanciación del modelo para el entrenamiento\n",
        "Se instancia el objeto en donde van a cargar los métodos y atributos que harán el entrenamiento y ajuste para crear un modelo de aprendizaje de máquina.\n",
        "\n",
        "En este caso ```LinearRegression``` es una instancia de la clase ```LinearRegression```, que contiene el algoritmo para obtener los coeficientes de mínimos de cuadrados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY7ATuo9kvDS"
      },
      "source": [
        "lr = LinearRegression()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw2GztJ60TTi"
      },
      "source": [
        "\n",
        "\n",
        "## Ajuste del modelo\n",
        "\n",
        "Para ejecutar el algoritmo se hace a través de un método llamado **fit**.\n",
        "\n",
        "Una vez hecha una separación de entrenamiento y de prueba, realizamos el ajuste o entrenamiento, es decir, a partir de una muestra de los datos se van a obtener los coeficientes que minimizan el error.\n",
        "\n",
        "Estos coeficientes define un modelo específico generado por esos datos. Por claridad lo vamos a guardar en una objeto llamado lr_model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdttOM8n0TTj"
      },
      "source": [
        "lr_model = lr.fit(X_train, y_train)\n",
        "print ('Coeficientes: ',  lr_model.intercept_, lr_model.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBCaynZH0TTn"
      },
      "source": [
        "\n",
        "\n",
        "## Predicción\n",
        "\n",
        "Una vez que ha sido entrenado el modelo, podemos probar con una observación de una muestra diferente, o sea, con la muestra de prueba. Notese que la muestra de prueba no ha sido usada en el método fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t03MRmM3Kzhv"
      },
      "source": [
        "X_test[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBKMQ6gq0TTn"
      },
      "source": [
        "predictions_lr = lr_model.predict(X_test)\n",
        "predictions_lr[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqknY2KLK8KQ"
      },
      "source": [
        "X_test['prediction'] =  np.array(predictions_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_anBZMOfLv-y"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOKrOIfpfeDS"
      },
      "source": [
        "\n",
        "\n",
        "Observamos que el output del método **predict** es un array en donde están las predicciones de los valores de las casas.\n",
        "\n",
        "El output dependerá del problema, si es supervisado de regresión o de clasificación.\n",
        "\n",
        "¿Cómo sería el output en un contexto de apredizaje supervisado de clasificación? ¿Y de regresión? ¿Y de aprendizaje no supervisado?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxB7UzJx0TTs"
      },
      "source": [
        "\n",
        "\n",
        "## Elección de un métrica\n",
        "La métrica que se elige es para medir qué tan bien tu modelo va a predecir cuando se tengan datos no observados previamente. Más adelante veremos los detalles de las distintas métricas que existen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R2Cwpq30TTs"
      },
      "source": [
        "print ('Error medio absoluto: ', mean_absolute_error(y_test,predictions_lr))\n",
        "print ('Error cuadrático medio: ', mean_squared_error(y_test,predictions_lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyVmCPvuhR3o"
      },
      "source": [
        "\n",
        "\n",
        "## Conclusión\n",
        "\n",
        "Como se ha mencionado este es un ejemplo introductorio del marco de trabajo básico del que partiremos.\n",
        "A partir de aquí vamos a profundizar en cada uno de los pasos que hemos mencionado, a responder varias preguntas que han quedado inconclusas y estudiar problemas de naturaleza distinta como aprendizaje supervisado de clasificación, de regresión y apredizaje no supervisado."
      ]
    }
  ]
}