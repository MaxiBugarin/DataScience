{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_logistic_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/al34n1x/DataScience/blob/master/8.Machine_Learning/09_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9UahsNhWoR5"
      },
      "source": [
        "\n",
        "\n",
        "# Clasificación: Regresión Logística"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyT7BA-gbFub"
      },
      "source": [
        "La regresión logística nos permite resolver problemas con dos posibles estados “SI/NO”: binario o un número finito de “etiquetas” o “clases”: múltiple.\n",
        "Aunque el nombre Regresión logística sugiere una operación de regresión, el objetivo de la Regresión logística es la clasificación.\n",
        " \n",
        " Algunos Ejemplos de Regresión Logística son:\n",
        "\n",
        "* Clasificar si el correo que llega es Spam o No es Spam\n",
        "* Dados unos resultados clínicos de un tumor clasificar en “Benigno” o “Maligno”\n",
        "* El texto de un artículo a analizar es: Entretenimiento, Deportes, Política ó Ciencia\n",
        "* A partir de historial bancario conceder un crédito o no\n",
        "* Confiaremos en la implementación del paquete sklearn en Python para ponerlo en práctica.\n",
        "\n",
        "Lo que distingue a un modelo de regresión logística del modelo de regresión lineal es que la variable de resultado en la regresión logística es binaria o dicotómica\n",
        "\n",
        "Podemos ver en la siguiente figura que la salida de la regresión lineal pasa a través de una función de activación que puede mapear cualquier valor real entre 0 y 1.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/al34n1x/DataScience/master/img/lr_ltr.png)\n",
        "\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/al34n1x/DataScience/master/img/sigmoid.png)\n",
        "\n",
        "\n",
        "\n",
        "En este notebook vamos a estudiar los conceptos básicos de Clasificación y como podemos aplicarla usando la API de scikit-learn. Nos focalizaremos en Regresión Logística, pero veremos que es muy fácil aplicar otros algoritmos con la api de scikit-learn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOf10KvoWoTs"
      },
      "source": [
        "\n",
        "\n",
        "Para empezar, vamos a crear un dataset sintético que podamos aplicar en nuestro primer problema de clasificación.\n",
        "Será un problema de clasificación binaria en el que, para ir entendiendo los conceptos, sólo utilizaremos dos predictores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGVVTTZbWoSs"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import linear_model\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVQb8jXGWoTy"
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X, y = make_blobs(centers=2, random_state=0, n_samples=200)\n",
        "\n",
        "print('X ~ n_samples x n_features:', X.shape)\n",
        "print('y ~ n_labels:', y.shape)\n",
        "\n",
        "print('\\nFirst 5 samples:\\n', X[:5, :])\n",
        "print('\\nFirst 5 labels:', y[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR1ZaWysWoUE"
      },
      "source": [
        "\n",
        "\n",
        "Como hemos hecho que nuestros datos sean bidimiensionales, podemos mostrarlos en un plot 2D donde la primera característica corresponda al eje *x* y la segunda característica al eje *y*. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Vv71erWoUO"
      },
      "source": [
        "plt.scatter(X[y == 0, 0], X[y == 0, 1], s=40, label='0', marker='^')\n",
        "plt.scatter(X[y == 1, 0], X[y == 1, 1], s=40, label='1', c='orange', marker='x')\n",
        "\n",
        "plt.xlabel('first feature')\n",
        "plt.ylabel('second feature')\n",
        "plt.legend(loc='upper right');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYsKgIBBWoUi"
      },
      "source": [
        "\n",
        "\n",
        "Para evaluar los modelos que vamos a crear, vamos a separar el dataset en *train* y *test*. Recordemos que estos dos conjuntos nos permiten:\n",
        "\n",
        "1. **Training**: Ajustar el modelo a los datos de entrenamiento.\n",
        "2. **Test**: Evaluar la capacidad de generalizar del modelo.\n",
        "\n",
        "\n",
        "Para separar los dos conjuntos utilizamos la función `train_test_split` del módulo `model_selection`. Separaremos ambos conjuntos con un ratio de 75/25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSS8NCgNWoU6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.25,\n",
        "                                                    random_state=1234,\n",
        "                                                    stratify=y)   # Attention: we pass the \"y\" as the class label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzOsZAPlWoVb"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqhCMHGGWoVx"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq3sxHUxWoWQ"
      },
      "source": [
        "\n",
        "\n",
        "Todos los algoritmos implementados en scikit-learn están expuestos en su API mediante objetos de tipo *Estimator*, que garantiza que todos los modelos disponen de la misma API:\n",
        "\n",
        "- `Estimator.`**`fit(X, y)`**: ajusta los parámetros del modelo a los datos\n",
        "- `Estimator.`**`predict(X)`**: predice los valores de salida para datos nuevos\n",
        "- `Estimator.`**`score(X, y)`**: evalúa los resultados de la predicción\n",
        "\n",
        "Nosotros utilizaremos el objeto LogisticRegression para nuestra tarea de clasificación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwYFeXYOWoWX"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzi84HHTWoXB"
      },
      "source": [
        "\n",
        "\n",
        "Para entrenar el modelo, simplemente tenemos que llamar al método **`fit`** de nuestro objeto `classifier`, indicándole los datos de entrenamiento y las etiquetas asociadas a esos datos: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_ImFfP8WoXH"
      },
      "source": [
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ7ENisHXVWp"
      },
      "source": [
        "classifier.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bGzSX-yXaR_"
      },
      "source": [
        "classifier.intercept_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-UIs2zRWoXe"
      },
      "source": [
        "\n",
        "\n",
        "Una vez tenemos el modelo entrenado, podemos empezar a realizar predicciones con datos nuevos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN2GKQluWoXo"
      },
      "source": [
        "prediction = classifier.predict(X_test)\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m86uFb2RWoX_"
      },
      "source": [
        "classifier.predict_proba(X_test).round(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWed46rXWoYa"
      },
      "source": [
        "Podemos comparar visualmente las predicciones con los valores de $y$ reales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqzL5mobWoYf"
      },
      "source": [
        "print(prediction[:20])\n",
        "print(y_test[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI0nqWCzWoYr"
      },
      "source": [
        "\n",
        "\n",
        "Para evaluarlo cuantitativamente, podemos computar qué fracción de las predicciones es correcta. A esta métrica se le llama **accuracy**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgCPPHMqWoYv"
      },
      "source": [
        "np.mean(prediction == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c52jALRkWoY7"
      },
      "source": [
        "\n",
        "\n",
        "Por supuesto, scikit-learn nos provee la función **`score`** para computar el **accuracy** directamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZs4mD0IWoZD"
      },
      "source": [
        "classifier.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCd6ZtAnYnuF"
      },
      "source": [
        "classifier.score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUHxaEAiXuMt"
      },
      "source": [
        "#dir(classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzqbHT1bWoZp"
      },
      "source": [
        "\n",
        "\n",
        "Suele ser muy útil comparar la capacidad de generalización del modelo en el conjunto de test con el accuracy en los datos de entrenamiento (veremos por qué más adelante):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeHW3_oxWoaS"
      },
      "source": [
        "\n",
        "\n",
        "La Regresión Logística es un modelo linear, esto es, un modelo que crea una decisión que es lineal en el espacio de entrada. En nuestro dataset, esto significa que el umbral de decisión es una recta que separa las dos variables de entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcCd_SnZWoaW"
      },
      "source": [
        "#from seaborn import figures\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X[y == 0, 0], X[y == 0, 1], s=40, label='0', marker='^')\n",
        "plt.scatter(X[y == 1, 0], X[y == 1, 1], s=40, label='1', c='orange', marker='x')\n",
        "\n",
        "plt.xlabel(\"first feature\")\n",
        "plt.ylabel(\"second feature\")\n",
        "plt.legend(loc='upper right');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJs8rMKKMP4U"
      },
      "source": [
        "#from seaborn import figures\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot the decision boundary. For that, we will assign a color to each\n",
        "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "h = .02  # step size in the mesh\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "# Put the result into a color plot\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(1, figsize=(7, 4))\n",
        "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "\n",
        "\n",
        "plt.scatter(X[y == 0, 0], X[y == 0, 1], s=40, label='0', marker='^')\n",
        "plt.scatter(X[y == 1, 0], X[y == 1, 1], s=40, label='1', c='orange', marker='x')\n",
        "\n",
        "plt.xlabel(\"first feature\")\n",
        "plt.ylabel(\"second feature\")\n",
        "#mglearn.plot_2d_separator(classifier, X)\n",
        "plt.legend(loc='upper right');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWH9Z9bCWoaz"
      },
      "source": [
        "\n",
        "\n",
        "Podemos obtener otras métricas como F-Score, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXUIgmZxWoa2"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "print('Precision:', precision_score(y_test, prediction))\n",
        "print('Recall:   ', recall_score(y_test, prediction))\n",
        "print('Fscore:   ', f1_score(y_test, prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsYe6oJSWobC"
      },
      "source": [
        "\n",
        "\n",
        "Además es posible obtener los parámetros de la regresión:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcQ2NQYXWobH"
      },
      "source": [
        "print(classifier.coef_)\n",
        "print(classifier.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}