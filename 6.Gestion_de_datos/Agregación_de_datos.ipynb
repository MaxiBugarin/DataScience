{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Agregación de datos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+Lw1Oi/gZmFtW4OGL2+nk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/al34n1x/DataScience/blob/master/6.Gestion_de_datos/Agregaci%C3%B3n_de_datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb_FkSc60JDN",
        "colab_type": "toc"
      },
      "source": [
        ">[Agregación de datos y operaciones de grupo](#scrollTo=BFynk27lvXm6)\n",
        "\n",
        ">>[Actividades que veremos en este apartado](#scrollTo=EMGwZJuAv306)\n",
        "\n",
        ">>>[Mecánica del GroupBy](#scrollTo=F1ju7vADwWy1)\n",
        "\n",
        ">>>[Seleccionando una columna o subset de columnas](#scrollTo=_SAtsTx-1xjS)\n",
        "\n",
        ">>>[Agrupando con dicts y series](#scrollTo=SFpRZZb23nOj)\n",
        "\n",
        ">>>[Agrupación con funciones](#scrollTo=hNvhRjQg5IhT)\n",
        "\n",
        ">>>[Data Aggregation](#scrollTo=tCCi7PrE5ecH)\n",
        "\n",
        ">>>[Aplicación de columna inteligente y de funciones múltiples](#scrollTo=rbeK_M1blP_0)\n",
        "\n",
        ">>[Aplicar: general dividir-aplicar-combinar](#scrollTo=K8sgtonjqmcI)\n",
        "\n",
        ">>>[Análisis de cuantiles y buckets](#scrollTo=mFfqx7P0sbeq)\n",
        "\n",
        ">>>[Rellenar valores perdidos con valores específicos de grupo](#scrollTo=tvKXddD9tV0C)\n",
        "\n",
        ">>[Muestreo aleatorio y permutación](#scrollTo=vTsm2BuHv_SC)\n",
        "\n",
        ">>>[Promedio ponderado grupal y correlación](#scrollTo=eX6B4Plhxr8P)\n",
        "\n",
        ">>[Pivot Tables y tabulación cruzada](#scrollTo=3e5jR8qh0UMW)\n",
        "\n",
        ">>>[Tabulaciones cruzadas (crosstab)](#scrollTo=gprrjJ0m12nf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFynk27lvXm6",
        "colab_type": "text"
      },
      "source": [
        "# Agregación de datos y operaciones de grupo\n",
        "\n",
        "La categorización de un conjunto de datos y la aplicación de una función a cada grupo, ya sea una agregación o transformación, es un componente crítico del trabajo de análisis de datos. Después de cargar, fusionar y preparar un conjunto de datos, es posible que debas calcular estadísticas de grupo o posiblemente tablas dinámicas para fines de informes o visualización. Pandas proporciona una interfaz de grupo flexible, que te permite cortar, y resumir conjuntos de datos de forma natural.\n",
        "\n",
        "Como verás, con la expresividad de Python y pandas, podemos realizar operaciones grupales bastante complejas utilizando cualquier función que acepte un objeto pandas o una matriz NumPy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMGwZJuAv306",
        "colab_type": "text"
      },
      "source": [
        "## Actividades que veremos en este apartado\n",
        "\n",
        "* Dividir un objeto pandas en pedazos usando una o más claves (en forma de funciones, matrices o nombres de columna de DataFrame)\n",
        "\n",
        "* Calcular estadísticas de resumen de grupo, como conteo, media o desviación estándar, o una función definida por el usuario\n",
        "\n",
        "* Aplique transformaciones dentro del grupo u otras manipulaciones, como normalización, regresión lineal, clasificación o selección de subconjuntos\n",
        "\n",
        "* Calcular tablas dinámicas y tabulaciones cruzadas\n",
        "\n",
        "* Realizar análisis cuantiles y otros análisis de grupos estadísticos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1ju7vADwWy1",
        "colab_type": "text"
      },
      "source": [
        "### Mecánica del GroupBy\n",
        "\n",
        "Existe un término conocido entre los analistas que describe operaciones de grupo, *split-apply-combine* \n",
        "En la primera parte de este proceso dividimos (split) dataframes o series en grupos basados en una o más keys. Una vez realizado la división, realizamos la función *apply* a cada grupo, produciendo un nuevo valor. \n",
        "Finalmente, tomamos el resultado de esas operaciones y las combinamos en un objeto.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/al34n1x/DataScience/master/img/split-apply-combine.png)\n",
        "\n",
        "*source: Python for Data Analysis, 2nd Edition*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbOGS3vovXEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n",
        "                   'key2' : ['one', 'two', 'one', 'two', 'one'],\n",
        "                   'data1' : np.random.randn(5),\n",
        "                   'data2' : np.random.randn(5)})\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxNpTDnDzAOt",
        "colab_type": "text"
      },
      "source": [
        "Supongamos que deseas calcular la media *(mean())* de la columna data1 usando las etiquetas de key1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip7mww3yyqBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped = df['data1'].groupby(df['key1'])\n",
        "grouped"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTPAa6D8yrYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5CsULB8zhw7",
        "colab_type": "text"
      },
      "source": [
        "Aquí agrupamos los datos usando dos claves, y la Serie resultante ahora tiene un índice jerárquico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9IChMQuzjNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "media = df['data1'].groupby([df['key1'], df['key2']]).mean()\n",
        "media"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q09b12lzugW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "media.unstack()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvowjZ25z3RS",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente ejemplo todo el grupo de keys son series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPb4TiJa0N1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prov = np.array(['Buenos Aires', 'Buenos Aires', 'Córdoba', 'Córdoba', 'Tucumán'])\n",
        "anios = np.array([2005, 2005, 2005, 2006, 2006])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xjS2CeIVBSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['data1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-AeL8DO0SUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['data1'].groupby([prov, anios]).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SAtsTx-1xjS",
        "colab_type": "text"
      },
      "source": [
        "### Seleccionando una columna o subset de columnas\n",
        "\n",
        "La indexación de un objeto **GroupBy** creado a partir de un DataFrame con un nombre de columna o matriz de nombres de columna, genera un subconjunto de columnas para la agregación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ock1N3TL2BWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.groupby('key1')['data1'] # Equivalente a df['data1'].groupby(df['key1'])\n",
        "df.groupby('key1')['data2'] # Equivalente a df[['data2']].groupby(df['key1'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHeua-rw2ghN",
        "colab_type": "text"
      },
      "source": [
        "Especialmente para grandes conjuntos de datos, puede ser conveniente agregar solo unas pocas columnas. Por ejemplo, en el conjunto de datos anterior, para calcular medios solo para la columna data2 y obtener el resultado como un DataFrame, podríamos escribir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei1BEtyD3OFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.groupby(['key1', 'key2'])[['data2']].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_Dgzoor3tU7",
        "colab_type": "text"
      },
      "source": [
        "El objeto devuelto por esta operación de indexación es un DataFrame agrupado. Sera una lista o matriz o una Serie agrupada si solo se pasa un solo nombre de columna como escalar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWWVxT0p3y8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_grouped = df.groupby(['key1', 'key2'])['data2']\n",
        "s_grouped.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFpRZZb23nOj",
        "colab_type": "text"
      },
      "source": [
        "### Agrupando con dicts y series\n",
        "\n",
        "Puede que necesites agrupar información existente en algo diferente a un arreglo. Consideremos el siguiente Dataframe:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZpC2fry32bX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "people = pd.DataFrame(np.random.randn(5, 5),\n",
        "                      columns=['a', 'b', 'c', 'd', 'e'],\n",
        "                      index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])\n",
        "people"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7STkNov37MX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "people.iloc[2:3, [1, 2]] = np.nan # Agrega un par de NaN\n",
        "people"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGWo6SRE4GbV",
        "colab_type": "text"
      },
      "source": [
        "Supongamos que tenemos una lista de columnas que corresponden a ese dataframe y queremos realizar una operacion **sum** entre las columnas por grupo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjnm__b-4Rl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mapping = {'a': 'red', 'b': 'red', 'c': 'blue',\n",
        "           'd': 'blue', 'e': 'red', 'f' : 'orange'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFGdcnqY4lzh",
        "colab_type": "text"
      },
      "source": [
        "Ahora podemos construir un arreglo a partir del dict y se lo pasamos a la operación **groupby**, pero en cambio le pasamos directamente el dict como key.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjeylfWs4Uoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "by_column=people.groupby(mapping, axis=1)\n",
        "by_column.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNvhRjQg5IhT",
        "colab_type": "text"
      },
      "source": [
        "### Agrupación con funciones\n",
        "El uso de las funciones de Python es una forma más genérica de definir un mapeo de grupo en comparación con un dict o Series. Cualquier función que se pase como clave de grupo se llamará una vez por valor de índice, y los valores de retorno se utilizarán como nombres de grupo. Más concretamente, consideremos el DataFrame de ejemplo de la sección anterior, que tiene los nombres de las personas como valores de índice. Supongamos que deseas agrupar por la longitud de los nombres; Si bien podrías calcular una matriz de longitudes de cadena, es más simple simplemente pasar la función len:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27Aaa4WO5VPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "people.groupby(len).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCCi7PrE5ecH",
        "colab_type": "text"
      },
      "source": [
        "### Data Aggregation\n",
        "Las agregaciones se refieren a cualquier transformación de datos que produce valores escalares a partir de matrices. Los ejemplos anteriores han utilizado varios de ellos, incluidos la media, el recuento, el mínimo y la suma. \n",
        "\n",
        "\n",
        "Function name |\tDescription\n",
        "------------- | -----------\n",
        "count\t| Número de valores no-NA en el grupo\n",
        "sum\t| Suma de valores no-NA\n",
        "mean\t| Media de valores no-NA \n",
        "median\t| Mediana aritmética de valores no-NA\n",
        "std, var\t| Desviación y varianza estándar imparcial (denominador n - 1)\n",
        "min, max\t| Mínimo y máximo de valores no-NA\n",
        "prod\t| Producto de valores no-NA \n",
        "first, last\t| Primer y último valores no-NA \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HRjvU8BkhEw",
        "colab_type": "text"
      },
      "source": [
        "Puedes usar agregaciones de tu propio diseño y, además, llamar a cualquier método que también esté definido en el objeto agrupado. Por ejemplo, puedes recordar que el cuantil calcula los cuantiles de muestra de una serie o las columnas de un marco de datos.\n",
        "\n",
        "Si bien el cuantil no se implementa explícitamente para GroupBy, es un método de la Serie y, por lo tanto, está disponible para su uso. Internamente, GroupBy corta eficientemente la serie, llama a **piece.quantile(0.9)** para cada pieza y luego ensambla esos resultados en el objeto de resultado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5xgcSpEkuCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC8mpPB3kyss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped = df.groupby('key1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXzHSQdBk1yf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped['data1'].quantile(0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PN0m7golB7F",
        "colab_type": "text"
      },
      "source": [
        "Puedes notar que algunos métodos como describe también funcionan, aunque no son agregaciones, estrictamente hablando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BC4f_1AlC-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbeK_M1blP_0",
        "colab_type": "text"
      },
      "source": [
        "### Aplicación de columna inteligente y de funciones múltiples\n",
        "\n",
        "Volvamos al conjunto de datos de propinas de ejemplos anteriores. Después de cargarlo con read_csv, agregamos una columna de porcentaje de propina tip_pct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1WKcHx3lkaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prop = pd.read_csv('https://raw.githubusercontent.com/al34n1x/DataScience/master/6.Gestion_de_datos/tips.csv')\n",
        "prop['tip_pct'] = prop['tip'] / prop ['total_bill']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD_0UR4Ol43g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prop[:6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9NcYdlfmD6B",
        "colab_type": "text"
      },
      "source": [
        "Como hemos visto, agregar una Serie o todas las columnas de un dataframe de datos es una cuestión de utilizar el agregado con la función deseada o llamar a un método como **mean** o **std**. \n",
        "Sin embargo, es posible que desees agregar usando una función diferente dependiendo de la columna, o múltiples funciones a la vez. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXZCz3IDmS8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped = prop.groupby(['day', 'smoker'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtbQj7SKmXHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped_pct = grouped['tip_pct']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vuJY47Qm03p",
        "colab_type": "text"
      },
      "source": [
        "Ten en cuenta que para estadísticas descriptivas como las de la Tabla que hemos compartido al comienzo, puedes pasar el nombre de la función como una cadena, en este caso 'mean'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHa_6xHZmaRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped_pct.agg('mean')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gSfupXLnE8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped_pct.agg(['min','max'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyIqaqvsn0Zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def peak_to_peak(arr):      # Funcion de agregación propia \n",
        "  return arr.max() - arr.min()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqBj-xNqnPXK",
        "colab_type": "text"
      },
      "source": [
        "Si pasas una lista de funciones o nombres de funciones, obtiene un DataFrame con nombres de columnas tomados de las funciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOHUzldHnRae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped_pct.agg(['mean', 'std', peak_to_peak])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWgyXT6spYjh",
        "colab_type": "text"
      },
      "source": [
        "Aquí pasamos una lista de funciones de agregación a **agg** para evaluar de forma independiente en los grupos de datos.\n",
        "\n",
        "No necesita aceptar los nombres que GroupBy le da a las columnas; en particular, las funciones lambda tienen el nombre '<lambda>', lo que hace que sean difíciles de identificar. Por lo tanto, si pasas una lista de tuplas (nombre, función), el primer elemento de cada tupla se usará como los nombres de columna de DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF7C15LrpjbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped_pct.agg([('foo', 'mean'), ('bar', np.std)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDb9RIsnpuLQ",
        "colab_type": "text"
      },
      "source": [
        "Con un DataFrame tienes más opciones, ya que puedes especificar una lista de funciones para aplicar a todas las columnas o diferentes funciones por columna. Para comenzar, supongamos que deseamos calcular las mismas tres estadísticas para las columnas tip_pct y total_bill"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO-aMmUXp0Xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "functions = ['count', 'mean', 'max'] # Lista de funciones"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGLZlt6Kp2NW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = grouped['tip_pct', 'total_bill'].agg(functions)\n",
        "\n",
        "'''\n",
        "A las dos columnas del DF le aplicamos las tres funciones\n",
        "'''\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ5JSdBRqLzX",
        "colab_type": "text"
      },
      "source": [
        "Ahora, supongamos que deseamos aplicar funciones potencialmente diferentes a una o más de las columnas. Para hacer esto, pasamos un dict a *agg* que contenga una asignación de nombres de columna a cualquiera de las especificaciones de funciones enumeradas hasta ahora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xc-DJrSqTS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped.agg({'tip' : np.max, 'size' : 'sum'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgAUwiEbqbHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped.agg({'tip_pct' : ['min', 'max', 'mean', 'std'],\n",
        "             'size' : 'sum'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8sgtonjqmcI",
        "colab_type": "text"
      },
      "source": [
        "## Aplicar: general dividir-aplicar-combinar\n",
        "\n",
        "El método mas general de uso de GroupBy es apply.\n",
        "Como se ilustra en la Figura, apply divide el objeto que se está manipulando en piezas, invoca la función pasada en cada pieza y luego intenta concatenar las piezas juntas.\n",
        "![alt text](https://raw.githubusercontent.com/al34n1x/DataScience/master/img/split-apply-combine.png)\n",
        "\n",
        "*source: Python for Data Analysis, 2nd Edition*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3MjcKzCrDoJ",
        "colab_type": "text"
      },
      "source": [
        "Supongamos que deseamos seleccionar los cinco valores principales de **tip_pct** por grupo. Primero, escribimos una función que seleccione las filas con los valores más grandes en una columna particular:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7T43e2srIUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top(df, n=5, column='tip_pct'):\n",
        "  return df.sort_values(by=column)[-n:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XuuZpwPrOq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top(prop, n=6) # Llamada a la función top"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQPuyS4mrbAe",
        "colab_type": "text"
      },
      "source": [
        "Ahora, si agrupamos por fumador, por ejemplo, y aplicamos *call* con esta función, obtenemos lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-AxvCDardci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prop.groupby('smoker').apply(top) # apply llama a la función top"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbzqRzSXrpli",
        "colab_type": "text"
      },
      "source": [
        "¿Qué ha pasado aquí? La función superior se llama en cada grupo de filas desde el DF, y luego los resultados se pegan usando *pandas.concat*, etiquetando las piezas con los nombres de los grupos. Por lo tanto, el resultado tiene un índice jerárquico cuyo nivel interno contiene valores de índice del DataFrame original."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgR1Gdaer7qP",
        "colab_type": "text"
      },
      "source": [
        "Si pasas una función a *apply* que toma otros argumentos o palabras clave, puedes pasarlos después de la función:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3N2uRwer1rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prop.groupby(['smoker', 'day']).apply(top, n=1, column='total_bill')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFfqx7P0sbeq",
        "colab_type": "text"
      },
      "source": [
        "### Análisis de cuantiles y buckets\n",
        "\n",
        "Pandas tiene algunas herramientas, en particular *cut* y *qcut*, para dividir los datos en cubos con contenedores de tu elección o por cuantiles de muestra. La combinación de estas funciones con *groupby* hace que sea conveniente realizar análisis de buckets o cuantil en un conjunto de datos. Considere un conjunto de datos aleatorio simple y una categorización de bucket de igual longitud usando cut:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP3INoKgsqpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frame = pd.DataFrame({'data1': np.random.randn(1000),\n",
        "                      'data2': np.random.randn(1000)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0QizzlostA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quartiles = pd.cut(frame.data1, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6-3UJN6swtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quartiles[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJnuec9Os4c4",
        "colab_type": "text"
      },
      "source": [
        "El objeto  devuelto por *cut* se puede pasar directamente a *groupby*. Entonces podríamos calcular un conjunto de estadísticas para la columna data2 de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmn-OJd_s-zC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stats(group):\n",
        "  return {'min': group.min(), 'max': group.max(),\n",
        "          'count': group.count(), 'mean': group.mean()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cc-cqTttFds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped = frame.data2.groupby(quartiles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnM8DT4ltJz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped.apply(get_stats) # que puedo agregar para que se vea mejor? ..un___..?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvKXddD9tV0C",
        "colab_type": "text"
      },
      "source": [
        "### Rellenar valores perdidos con valores específicos de grupo\n",
        "\n",
        "Al limpiar los datos faltantes, en algunos casos reemplazarás las observaciones de datos usando *dropna*, pero en otros puedes querer completar los valores nulos (NA) usando un valor fijo o algún valor derivado de los datos. *fillna* es la herramienta adecuada para usar; por ejemplo, aquí rellenamos los valores de NA con la media:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEghGmXztln2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = pd.Series(np.random.randn(6))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKZtrLBxtnbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s[:3] = np.nan\n",
        "s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBnIaGGVt--k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s.fillna(s.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUaBCYRUuKyv",
        "colab_type": "text"
      },
      "source": [
        "Supongamos que necesitas que el valor de relleno varíe según el grupo. Una forma de hacer esto es agrupar los datos y usar *apply* con una función que llame a *fillna* en cada fragmento de datos. Aquí hay algunos datos de muestra sobre los estados de EE. UU. Divididos en regiones orientales y occidentales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48_FJtkxuKbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states = ['Ohio', 'New York', 'Vermont', 'Florida',\n",
        "          'Oregon', 'Nevada', 'California', 'Idaho']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR-6KbEhuWCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# group_key = ['East'] * 4 + ['West'] * 4 # Notación alternativa\n",
        "group_key = ['East', 'East', 'East', 'East', 'West', 'West', 'West', 'West']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkyD6IrZuwIZ",
        "colab_type": "text"
      },
      "source": [
        "Ten en cuenta que la sintaxis ['Este'] * 4 produce una lista que contiene cuatro copias de los elementos en ['Este']."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfB2c5CKudH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.Series(np.random.randn(8), index=states)\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28UwIWF0ud2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[['Vermont', 'Nevada', 'Idaho']] = np.nan\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yTq_O1UvBUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.groupby(group_key).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmSiIdUiv2Al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fill_mean = lambda g: g.fillna(g.mean()) # Que hace esta funcion lambda?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtgvWzauv3Kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.groupby(group_key).apply(fill_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTsm2BuHv_SC",
        "colab_type": "text"
      },
      "source": [
        "## Muestreo aleatorio y permutación\n",
        "Supongamos que deseas extraer una muestra aleatoria (con o sin reemplazo) de un gran conjunto de datos para fines de simulación o alguna otra aplicación. Hay varias formas de realizar los \"sorteos\"; Aquí usamos el método de muestra para Series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrv7LxovwLtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hearts, Spades, Clubs, Diamonds\n",
        "suits = ['H', 'S', 'C', 'D']\n",
        "card_val = (list(range(1, 11)) + [10] * 3) * 4\n",
        "base_names = ['A'] + list(range(2, 11)) + ['J', 'K', 'Q']\n",
        "cards = []\n",
        "for suit in ['H', 'S', 'C', 'D']:\n",
        "    cards.extend(str(num) + suit for num in base_names) # Para cada letra itera por la cantidad de cartas\n",
        "\n",
        "deck = pd.Series(card_val, index=cards)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PEqZwzrwoU-",
        "colab_type": "text"
      },
      "source": [
        "Así que ahora tenemos una Serie de longitud 52 cuyo índice contiene nombres y valores de cartas que se usan en Blackjack y otros juegos (para simplificar las cosas, solo dejo que el as 'A' sea 1):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoBJmzN7wnsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deck[:13]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHC2mGROw6uV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw(deck, n=5):\n",
        "  return deck.sample(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrVSBDX-w8tE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw(deck)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3y_qbANxJsG",
        "colab_type": "text"
      },
      "source": [
        "Supongamos que quieres dos cartas al azar de cada palo. Debido a que el palo es el último personaje de cada nombre de tarjeta, podemos agruparlo en base a esto y usar apply:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg1oKwaIw8vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_suit = lambda card: card[-1] # ultima letra es el palo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P0sqXj0xRhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deck.groupby(get_suit).apply(draw, n=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX6B4Plhxr8P",
        "colab_type": "text"
      },
      "source": [
        "### Promedio ponderado grupal y correlación\n",
        "\n",
        "Bajo el paradigma de *split-apply-combine* de groupby, las operaciones entre columnas en un DataFrame o dos Series, como un promedio ponderado de grupo, son posibles.\n",
        "Consideremos un conjunto de datos financieros originalmente obtenido de Yahoo! Finance que contiene precios al final del día para algunas acciones y el índice S&P 500 (el símbolo SPX):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu2M02OHyBVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "close_px = pd.read_csv('https://raw.githubusercontent.com/al34n1x/DataScience/master/6.Gestion_de_datos/stocks.csv', \n",
        "                       parse_dates=True,index_col=0)\n",
        "close_px.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg0NfncTyd_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "close_px[-5:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH-rN_cZyqjF",
        "colab_type": "text"
      },
      "source": [
        "Una tarea de interés podría ser calcular un DataFrame que consta de las correlaciones anuales de los rendimientos diarios con SPX. \n",
        "Como una forma de hacer esto, primero creamos una función que calcula la correlación por pares de cada columna con la columna 'SPX':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WTxhA2KyvpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spx_corr = lambda x: x.corrwith(x['SPX'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2f0ofBzy2e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rets = close_px.pct_change().dropna() #Calculamos el procentaje de cambio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyS6K-bdy9Id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_year = lambda x: x.year\n",
        "by_year = rets.groupby(get_year) # Agrupamos los porcentajes de cambio por año\n",
        "by_year.apply(spx_corr) # Llama a la funcion spx_corr para calcular la correlación de cada columna "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e5jR8qh0UMW",
        "colab_type": "text"
      },
      "source": [
        "## Pivot Tables y tabulación cruzada\n",
        "\n",
        "Una tabla dinámica es una herramienta de resumen de datos que se encuentra con frecuencia en programas de hojas de cálculo. \n",
        "Agrega una tabla de datos por una o más claves, organizando los datos en un rectángulo con algunas de las claves de grupo a lo largo de las filas y algunas a lo largo de las columnas. \n",
        "Las tablas dinámicas en Python con pandas son posibles a través de la función *groupby*. DataFrame tiene un método *pivot_table* y también hay una función *pandas.pivot_table* de nivel superior. Además de proporcionar una interfaz conveniente para *groupby*, *pivot_table* puede agregar totales parciales, también conocidos como márgenes.\n",
        "\n",
        "Volviendo al conjunto de datos de propinas, supongamos que deseamos calcular una tabla de medios grupales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRbo_Gfj0sY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prop.pivot_table(index=['day', 'smoker'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sD_c5SG006b",
        "colab_type": "text"
      },
      "source": [
        "Ahora, supongamos que queremos aggregate solo *tip_pct* y *size*, y además agrupar por tiempo. Pondremos fumador en las columnas de la tabla y día en las filas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIGvHbai1Avl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prop.pivot_table(['tip_pct', 'size'], index=['time', 'day'],\n",
        "                 columns='smoker')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKEcTk2q1X3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prop.pivot_table('tip_pct', index=['time', 'size', 'smoker'],\n",
        "                 columns='day', aggfunc='mean', fill_value=0) # Si hay NaN podemos usar fill_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gprrjJ0m12nf",
        "colab_type": "text"
      },
      "source": [
        "### Tabulaciones cruzadas (crosstab)\n",
        "Una tabulación cruzada es un caso especial de una tabla dinámica que calcula las frecuencias de grupo. Aquí hay un ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTGc0xNm3JnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab([prop.time, prop.day], prop.smoker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekJQR3hh3ARM",
        "colab_type": "text"
      },
      "source": [
        "Podríamos aumentar esta tabla para incluir totales parciales pasando 'margins=true'. Esto tiene el efecto de agregar todas las etiquetas de fila y columna, siendo los valores correspondientes las estadísticas de grupo para todos los datos dentro de un solo nivel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9jNuUUX1_dF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab([prop.time, prop.day], prop.smoker, margins=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}